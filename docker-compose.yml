# Lecture Mind - Docker Compose
# IMPLEMENTS: v0.3.0 G4 - Docker image
#
# Usage:
#   docker-compose up        # Start the application
#   docker-compose up -d     # Start in background
#   docker-compose down      # Stop the application
#   docker-compose logs -f   # View logs
#   docker-compose build     # Rebuild the image
#
# Access: http://localhost:8000

services:
  lecture-mind:
    build:
      context: .
      dockerfile: Dockerfile
    image: lecture-mind:latest
    container_name: lecture-mind

    # Port mapping: host:container
    ports:
      - "8000:8000"

    # Environment variables
    environment:
      - HOST=0.0.0.0
      - PORT=8000
      # Model cache directories
      - HF_HOME=/app/cache/huggingface
      - TORCH_HOME=/app/cache/torch
      # Uncomment to use GPU (requires nvidia-docker)
      # - NVIDIA_VISIBLE_DEVICES=all

    # Volume mounts for persistence
    volumes:
      # Model cache (persist downloaded models between restarts)
      - lecture-mind-cache:/app/cache
      # Upload directory for processed videos
      - lecture-mind-uploads:/app/uploads
      # Optional: mount local videos for processing
      # - ./videos:/app/videos:ro

    # Resource limits (adjust based on your system)
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

    # Restart policy
    restart: unless-stopped

    # Health check (FastAPI endpoint)
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

# Named volumes for data persistence
volumes:
  lecture-mind-cache:
    driver: local
  lecture-mind-uploads:
    driver: local
