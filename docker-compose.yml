# Lecture Mind - Docker Compose
# IMPLEMENTS: v0.3.0 G4 - Docker image
#
# Usage:
#   docker-compose up        # Start the application
#   docker-compose up -d     # Start in background
#   docker-compose down      # Stop the application
#   docker-compose logs -f   # View logs

services:
  lecture-mind:
    build:
      context: .
      dockerfile: Dockerfile
    image: lecture-mind:latest
    container_name: lecture-mind

    # Port mapping: host:container
    ports:
      - "7860:7860"

    # Environment variables
    environment:
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=7860
      - GRADIO_ANALYTICS_ENABLED=false
      # Uncomment to use GPU (requires nvidia-docker)
      # - NVIDIA_VISIBLE_DEVICES=all

    # Volume mounts for persistence
    volumes:
      # Model cache (persist downloaded models)
      - lecture-mind-cache:/app/cache
      # Optional: mount local videos for processing
      # - ./videos:/app/videos:ro

    # Resource limits (adjust based on your system)
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

    # Restart policy
    restart: unless-stopped

    # Health check
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:7860/')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

# Named volumes for data persistence
volumes:
  lecture-mind-cache:
    driver: local
